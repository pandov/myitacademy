{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pandov/myitacademy-pandov/blob/master/FERFC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gWPFrNbx0tAG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%load_ext tensorboard\n",
        "num_classes = 5\n",
        "# ! sh colab.sh setup\n",
        "# ! dvc pull -d stages/BIOMETRY{num_classes}.dvc\n",
        "# ! unzip \"data/external/*.zip\"\n",
        "# ! dvc repro stages/BIOMETRY{num_classes}.dvc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lt15195-0tAn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# %%capture\n",
        "import torch\n",
        "# from catalyst.dl.utils import set_global_seed, prepare_cudnn\n",
        "# from src.kcv import CrossValidation, Experiment, experiment_run\n",
        "# from src.utils import get_fer_names, get_fc_fer_weights\n",
        "# from src.callbacks import *\n",
        "from src.features import BIOMETRY\n",
        "from src.models import FERFC\n",
        "# set_global_seed(7)\n",
        "# prepare_cudnn(deterministic=True)\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "# weight = get_fc_fer_weights(num_classes).to(device)\n",
        "from torchsummary import summary\n",
        "model = FERFC(5).to(device)\n",
        "summary(model, input_size=(1, 163))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pfgp9v9_0tA5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Ex1(Experiment):\n",
        "    def model(self): return FERFC(num_classes=num_classes, hidden_size=256)\n",
        "    def criterion(self): return torch.nn.CrossEntropyLoss(weight=weight)\n",
        "    def optimizer(self, model): return torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-5)\n",
        "    def scheduler(self, optimizer): return torch.optim.lr_scheduler.StepLR(optimizer, step_size=100, gamma=0.5)\n",
        "class Ex2(Ex1):\n",
        "    def model(self): return FERFC(num_classes=num_classes, hidden_size=512)\n",
        "    def optimizer(self, model): return torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
        "class Ex3(Ex1):\n",
        "    def optimizer(self, model): return torch.optim.Adam(model.parameters(), lr=2e-3, weight_decay=1e-5)\n",
        "class Ex4(Ex2):\n",
        "    def optimizer(self, model): return torch.optim.Adam(model.parameters(), lr=2e-3, weight_decay=1e-4)\n",
        "\n",
        "class Ex5(Ex3):\n",
        "    def model(self): return FERFC(num_classes=num_classes, hidden_size=1024)\n",
        "class Ex6(Ex4):\n",
        "    def model(self): return FERFC(num_classes=num_classes, hidden_size=1024)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-b8e2FTwfH4f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorboard --logdir logs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend"
        ],
        "id": "MpL4gN970tBU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%capture\n",
        "experiments = [Ex1(), Ex2(), Ex3(), Ex4(), Ex5(), Ex6()]\n",
        "class_names = get_fer_names(num_classes)\n",
        "callbacks = [\n",
        "    AccuracyCallback(num_classes=num_classes),\n",
        "    AUCCallback(num_classes=num_classes, class_names=class_names),\n",
        "    PrecisionRecallF1ScoreCallback(num_classes=num_classes, class_names=class_names),\n",
        "    ConfusionMatrixCallback(num_classes=num_classes, class_names=class_names),\n",
        "]\n",
        "cross_val = CrossValidation(BIOMETRY(num_classes), 4)\n",
        "logdir = f'logs/FERFC{num_classes}'\n",
        "experiment_run(experiments, callbacks, cross_val, logdir, device, 'f1/_mean', 100, 250)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VKPvMQ9g0tBe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! sh colab.sh save $logdir"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nLD7q4CZ0tBm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ! rm -r logs/FERFC5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bs2S1uWnTUbk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "orig_nbformat": 2,
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "FERFC.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}